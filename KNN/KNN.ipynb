{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da757590",
      "metadata": {
        "id": "da757590"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "85e1aeb5",
      "metadata": {
        "id": "85e1aeb5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a84c96df",
      "metadata": {
        "id": "a84c96df"
      },
      "source": [
        "# Creating the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61d70cd2",
      "metadata": {
        "id": "61d70cd2"
      },
      "outputs": [],
      "source": [
        "# Sepehr Moniri : 981813205\n",
        "\n",
        "# x is the set of data's features\n",
        "# y is the set of the data\n",
        "x, y = make_classification(n_samples=20000, n_features=8, random_state=981813205)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "205e29ef",
      "metadata": {
        "id": "205e29ef",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=981813205)\n",
        "\n",
        "split = 0.8 # spliting into 80% Training set and 20% test set\n",
        "split_number = int(np.ceil(x.shape[0] * split))\n",
        "x_train, y_train = x[0:split_number, :], y[0:split_number]\n",
        "x_test, y_test = x[split_number:, :], y[split_number:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad5a8ec",
      "metadata": {
        "id": "cad5a8ec"
      },
      "source": [
        "# Implementing the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9373112c",
      "metadata": {
        "id": "9373112c"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, n_neighbors=5, weights='uniform', metric='euclidean'):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def manhattan_distance(self, x1, x2):\n",
        "        return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "    # Initiling the metric\n",
        "    def get_distance(self, x1, x2):\n",
        "        if self.metric == 'euclidean':\n",
        "            return self.euclidean_distance(x1, x2)\n",
        "\n",
        "        elif self.metric == 'manhattan':\n",
        "            return self.manhattan_distance(x1, x2)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid metric\")\n",
        "\n",
        "    # Defining the dataset\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # calculating the distance of each item in test dataset with all datas in train dataset\n",
        "            distances = [self.get_distance(x, x_train) for x_train in self.X_train]\n",
        "\n",
        "            sorted_indices = np.argsort(distances)\n",
        "            k_nearest_indices = sorted_indices[:self.n_neighbors]\n",
        "            k_nearest_labels = self.y_train[k_nearest_indices]\n",
        "\n",
        "            # Initialing the weights\n",
        "            if self.weights == 'uniform':\n",
        "                prediction = np.argmax(np.bincount(k_nearest_labels))\n",
        "\n",
        "            elif self.weights == 'distance':\n",
        "                weights = 1 / (np.array(distances)[k_nearest_indices] + 1e-10)\n",
        "                weights /= np.sum(weights)\n",
        "                weighted_labels = np.zeros(max(k_nearest_labels) + 1)\n",
        "\n",
        "                for label, weight in zip(k_nearest_labels, weights):\n",
        "                    weighted_labels[label] += weight\n",
        "\n",
        "                prediction = np.argmax(weighted_labels)\n",
        "\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff81d1c3",
      "metadata": {
        "id": "ff81d1c3"
      },
      "source": [
        "# Algorithm setup and Predication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b0e7d2ee",
      "metadata": {
        "id": "b0e7d2ee"
      },
      "outputs": [],
      "source": [
        "knn = KNN(n_neighbors=3, weights='uniform', metric='manhattan')\n",
        "# knn = KNN(3, weights=\"distance\", metric=\"manhattan\")\n",
        "knn.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "056f64aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "056f64aa",
        "outputId": "08902bb5-fa5a-475e-821e-ec9c633e5716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN predictions: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "y_pred = knn.predict(x_test)\n",
        "print(\"KNN predictions:\", y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a05b16",
      "metadata": {
        "id": "74a05b16"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6213f1fc",
      "metadata": {
        "id": "6213f1fc"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bca748ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bca748ae",
        "outputId": "2bb05ad2-fb80-4c09-cdb4-bd10d866fd3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8725\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50f72aa6",
      "metadata": {
        "id": "50f72aa6"
      },
      "source": [
        "# Improvments\n",
        "For imporoving the implemented algorithm, we should check all possible ways that the parameters like weights and metric could stand together untile we find a compination that the accuracy is the best of them. For finding that compination, we try all values of the parameters along with a cerain number of neighbors (here I set it to [3,5,7,9]).\n",
        "At the end the 'improvment' function will give us an combination of parameters that have a best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "274fd549",
      "metadata": {
        "id": "274fd549"
      },
      "outputs": [],
      "source": [
        "def improvment(param_grid, accuracy_func, imp_alg):\n",
        "    best_accuracy = 0\n",
        "    best_params = {}\n",
        "\n",
        "    for n_neighbors in param_grid['n_neighbors']:\n",
        "        for weights in param_grid['weights']:\n",
        "            for metric in param_grid['metric']:\n",
        "                # Initialize KNN model with current parameters\n",
        "                model = imp_alg(n_neighbors=n_neighbors, weights=weights, metric=metric) # , algorithm=algorithm\n",
        "                model.fit(x_train, y_train)\n",
        "                y_pred = model.predict(x_test)\n",
        "                accuracy = accuracy_func(y_test, y_pred)\n",
        "\n",
        "                # Check if current parameters yield better accuracy\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_params = {\n",
        "                        'n_neighbors': n_neighbors,\n",
        "                        'weights': weights,\n",
        "                        'metric': metric\n",
        "                    }\n",
        "\n",
        "    return best_params, best_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cece406f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cece406f",
        "outputId": "ea40ceab-3831-42e4-f291-dabc63af01fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'n_neighbors': 9, 'weights': 'uniform', 'metric': 'manhattan'}, 0.885)\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "print(improvment(param_grid, accuracy, KNN))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1fde7f",
      "metadata": {
        "id": "5d1fde7f"
      },
      "source": [
        "The outputs here are tested on 2000 dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
